{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!pip install flask-ngrok\n",
        "!pip install pandas scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from pyngrok import ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "ngrok.set_auth_token(\"NGROK_AUTHTOKEN\") #replace with your authtoken code\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(5000)  # Port 5000 (default for Flask)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Welcome to the Manufacturing API!\"\n",
        "\n",
        "# Global variables to store data and model\n",
        "data = None\n",
        "model1 = None\n",
        "scaler = None\n",
        "\n",
        "# Upload Endpoint\n",
        "import os\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "        global data\n",
        "        try:\n",
        "            print(\"Request received\")\n",
        "            file = request.files.get('File')  # Use get() for safety\n",
        "\n",
        "            if file is None:\n",
        "                print(\"File not found in request\")\n",
        "                return jsonify({\"error\": \"File not found in request\"}), 400\n",
        "\n",
        "            print(\"File received:\", file.filename)\n",
        "            file_path = os.path.join('/content/', file.filename)\n",
        "\n",
        "            try:\n",
        "                file.save(file_path)\n",
        "                print(\"File saved:\", file_path)\n",
        "            except Exception as save_error:\n",
        "                print(\"Error saving file:\", save_error)\n",
        "                return jsonify({\"error\": f\"Error saving file: {save_error}\"}), 400\n",
        "\n",
        "            try:\n",
        "                data = pd.read_csv(file_path)\n",
        "                print(\"File read successfully\")\n",
        "                return jsonify({\"message\": \"File uploaded successfully!\", \"columns\": list(data.columns)})\n",
        "            except Exception as read_error:\n",
        "                print(\"Error reading file:\", read_error)\n",
        "                return jsonify({\"error\": f\"Error reading file: {read_error}\"}), 400\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"General error:\", e)\n",
        "            return jsonify({\"error\": str(e)}), 400\n",
        "\n",
        "# Train Endpoint\n",
        "@app.route('/train', methods=['POST'])\n",
        "def train():\n",
        "    global model1, data, scaler\n",
        "    if data is None:\n",
        "        return jsonify({\"error\": \"No data uploaded. Please upload data first.\"}), 400\n",
        "\n",
        "    if scaler is None:\n",
        "        scaler = MinMaxScaler()\n",
        "\n",
        "    # Ensure required columns are in the dataset\n",
        "    required_columns = ['Date', 'Machine_ID', 'Assembly_Line_No', 'Hydraulic_Pressure(bar)',\n",
        "       'Coolant_Pressure(bar)', 'Air_System_Pressure(bar)',\n",
        "       'Coolant_Temperature', 'Hydraulic_Oil_Temperature(?C)',\n",
        "       'Spindle_Bearing_Temperature(?C)', 'Spindle_Vibration(?m)',\n",
        "       'Tool_Vibration(?m)', 'Spindle_Speed(RPM)', 'Voltage(volts)',\n",
        "       'Torque(Nm)', 'Cutting(kN)', 'Downtime']\n",
        "    if not all(col in data.columns for col in required_columns):\n",
        "        return jsonify({\"error\": f\"Dataset must contain columns: {required_columns}\"}), 400\n",
        "\n",
        "    # Split data into features and target\n",
        "    df = pd.DataFrame(data)\n",
        "    df.drop(columns=['Date','Machine_ID','Assembly_Line_No'],axis=1,inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    df.loc[df['Downtime']=='Machine_Failure','Downtime']=1\n",
        "    df.loc[df['Downtime']=='No_Machine_Failure','Downtime']=0\n",
        "    df['Downtime'] = pd.to_numeric(df['Downtime'])\n",
        "    X=df.drop('Downtime',axis=1)\n",
        "    y=df['Downtime']\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=42)\n",
        "\n",
        "    #scaling\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    regressor=LogisticRegression()\n",
        "    model=regressor.fit(X_train,y_train)\n",
        "\n",
        "    #Tune the model\n",
        "    params={'C':[1,5,10,15,20,30,40,50],'max_iter':[100,150,200,300]}\n",
        "    model1=GridSearchCV(model,param_grid=params,scoring='f1',cv=5)\n",
        "    model1.fit(X_train,y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred=model1.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    return jsonify({\"message\": \"Model trained successfully!\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1})\n",
        "\n",
        "# Predict Endpoint\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    global model1, scaler\n",
        "    if model1 is None:\n",
        "        return jsonify({\"error\": \"Model not trained. Please train the model first.\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Get JSON input\n",
        "        input_data = request.get_json()\n",
        "        X_new = [[input_data[\"Hydraulic_Pressure(bar)\"],input_data[\"Coolant_Pressure(bar)\"],\n",
        "                  input_data[\"Air_System_Pressure(bar)\"],input_data[\"Coolant_Temperature\"],input_data[\"Hydraulic_Oil_Temperature(?C)\"],input_data[\"Spindle_Bearing_Temperature(?C)\"],input_data[\"Spindle_Vibration(?m)\"],\n",
        "                  input_data[\"Tool_Vibration(?m)\"],input_data[\"Spindle_Speed(RPM)\"],input_data[\"Voltage(volts)\"],input_data[\"Torque(Nm)\"],\n",
        "                  input_data[\"Cutting(kN)\"]]]\n",
        "\n",
        "        X_new = scaler.transform(X_new)\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = model1.predict(X_new)[0]\n",
        "        decision_values = model1.decision_function(X_new)\n",
        "        confidence = abs(decision_values[0])\n",
        "\n",
        "        return jsonify({\"Downtime\": \"Yes\" if prediction == 1 else \"No\", \"Confidence\": round(confidence, 2)})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 400\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "72VWNXaiX4bE",
        "outputId": "b2dcb590-3a98-4977-dd2b-25c161b4b5e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Public URL: NgrokTunnel: \"https://5d74-34-21-0-180.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:46:00] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:46:00] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:46:26] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request received\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:46:45] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File received: Machine Downtime.csv\n",
            "File saved: /content/Machine Downtime.csv\n",
            "File read successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:46:59] \"POST /train HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Jan/2025 18:47:34] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRMauauijf_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
